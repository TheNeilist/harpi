![a harpy](https://raw.githubusercontent.com/buchenberg/harpi/master/modules/core/client/img/brand/logo.png "Harpi")

# Harpi

Harpi is an HTTP Archive pipeline. It helps in documenting existing web API's by converting Har files to UML diagrams and Swagger documentation.


## Status

Harpi is far from complete. Most of the work is being done at the API level now. Here is what is supported so far:

* Create projects and upload har files to the project.
* Generate a distinct URL report on project HAR files.
* Generate Swagger from Har.
* Generate UML sequence diagrams from Har.
* Show Swagger specs in included Swagger UI.

## Goals

* Har to UML Class Diagram
* Har to Markdown documentation
* Add metadata to HAR like x-swagger-definition using form.
* Take advantage of versioning for the Swagger specs.
* Dredd testing for Swagger.
* Swagger UI extensions to handle legacy auth.

## Features

### UML Sequence Diagrams from Har

The sequence diagram can be used represent the communication flow between the User Agent (the browser client) and the various services. The diagram is generated by parsing the Har JSON. The diagram may be augmented by adding metadata to the Har file using the editor and clicking "Generate" again. The following sections describe the JSON elements and how they are used .

#### Participants

The first participant is always named 'User Agent'. All other participant names are derived from the path string in the entries[*]request.url. The Optional entries[]['x-service-name'] metadata extension will be used if it exists. A participant will be created for each entry where the names are different. If you have several entries for the same service you may give each the same x-service-name and they will combine to one participant.

#### Messages

In UML sequence diagrams messages look like methods with signatures e.g. getResouceById(id) or respond(resource). The UML request message names are generated using the entry request method and a resource name concatonated in Pascal case like postWidget or getWidgets. The request method is dirived from entries[*].request.method and the resource will be derived (guessed) from the last part of the path i.e /inventory/widgets becomes widgets. Optionaly, the x-resource-name metadata extention can be added to the entry.

## REST API

Verb | Path | Description
---|---|---
GET | /api/projects/{projectId} | Get project by id
GET | /api/projects/{projectId}?reportType=url | List URL's covered in project.
GET | /api/projects | List projects
POST | /api/projects | Create project
PUT | /api/projects | Update project
DELETE | /api/projects/{projectId}  | Delete project by id
GET | /api/hars/{harId} | Get har by id
GET | /api/hars | List hars
POST | /api/hars | Create har
POST | /api/hars/{harId}/specs | Create new spec from har by id and add ref to har
PUT | /api/hars/{harId} | Update har by id
DELETE | /api/hars/{harId} | Delete har by id
GET | /api/specs/{specId} | Get spec by id
GET | /api/specs | List specs
POST | /api/specs | Create spec
PUT | /api/specs/{specId} | Update spec by id
DELETE | /api/specs/{specId} | Delete spec by id

## Running in a Docker container

The main docker-compose.yml configuration is suitable for development. For running a development environment with live reload just run the following. By default docker-compose will use docker-compose.yml and the docker-compose.override.yml to build the stack.

```bash
docker-compose up -d
```

For Windows you will need to provide the docker-compose custom override like so.

```bash
docker-compose -f docker-compose.yml -f docker-compose.windows.yml up -d
```

Production environments have no shared volumes and no unnecessarily exposed ports.

```bash
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```
